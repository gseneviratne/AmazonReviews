{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../images/logo.png\" width=35% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "\n",
    "\n",
    " <font size= \"8\"><font color = #FF900>Subject: -<font color = #232F3E> Technologies of Advanced Programming\n",
    "    <br />\n",
    " <font size= \"8\"><font color = #FF900>Teacher: -<font color = #232F3E> Salvatore Nicotra\n",
    "    <br />\n",
    " <font size= \"8\"><font color = #FF900>Students: -<font color = #232F3E> Gayan Shakthi Seneviratne, Corrado Trigilia\n",
    "    <br />\n",
    " <font size= \"6\"><font color = #FF900>Academic year: -<font color = #232F3E> 2023/24\n",
    "    <br />\n",
    " \n",
    " <font size = 3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c5337",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color = #FF900> Introducing AmazonAIWatchdogs <font color = black>\n",
    "\n",
    "<font color = #FF9900>AmazonAIWatchdogs </font>\n",
    "\n",
    "<font color = #232F3E>\n",
    "is a tools for analyzing Amazon reviews and detecting if they have been generated by AI like ChatGPT and give a SentimentAnalysis by then. \n",
    "\n",
    "So, with AmazonAIWatchdogs, you can separate the human reviews from the AI-generated ones!\n",
    "</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90625908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color = #FF900> Platform Pipeline <font color = #232F3E>\n",
    "\n",
    "\n",
    "This is the entire structure that represented in the following schema.\n",
    "</font>\n",
    "\n",
    "<img src=\"../images/pipeline.jpeg\" width=50% style=\"margin-left:auto; margin-right:auto\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfca9b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color = #FF900> What kind of technologies was used?\n",
    "\n",
    "# <font color = #FF900> Python <font color = #232F3E>\n",
    "\n",
    "First of all, this is why we choose Python\n",
    "\n",
    "<img src=\"../meme/memepython.jpg\" width=50% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "\n",
    "With python we were able to achieve a Scraper system e most important a DetectAI scripts.\n",
    "The Scraper system use the BeautifulSoup library for extract data from HTML and/or XML documents. with\n",
    "this library you can navigate by the source code of a page and take data to analyze.\n",
    "\n",
    "example:\n",
    "        <code>  \n",
    "                #Leggo il codice HTML dato dall'URL in input\n",
    "                response = requests.get(product_url) \n",
    "                html_content = response.text\n",
    "                #BeautifulSoup analizzerà il codice HTML\n",
    "                soup = BeautifulSoup(html_content, 'html.parser')\n",
    "                #Trovo il \"tag div\" \"padre\" da cui poi estrapolo i vari div figli\n",
    "                divs = soup.find_all('div', {'class' : 'a-section review aok-relative'})\n",
    "        </code>\n",
    "\n",
    "For the DetectAI script we used a lybrary named 'model' that import the 'GPT2PPL' library.\n",
    "with this, we can insert a text into a function that automatically analyze the text and can understand\n",
    "if he is generated by AI or by HUMAN. Return value like: Perplexity or the max perplexity of each sentence(Burstiness).\n",
    "\n",
    "example:    <code> \n",
    "                #Funzione che restituisce il risultato sulla base del testo dato\n",
    "                def getResults(self, threshold):\n",
    "                if threshold < 60: #60\n",
    "                label = 0\n",
    "                return \"Il testo è generato da un'AI.\\n\", label\n",
    "                elif threshold < 80: #80\n",
    "                label = 0 \n",
    "                return \"Il Testo contiene molto probabilmente parti generati da un'AI.\\n\", label\n",
    "                else:\n",
    "                label = 1\n",
    "                return \"Il testo è scritto da un Umano.\\n\", label \n",
    "            </code>\n",
    "\n",
    "At Last with starter.py we can start all docker build. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf817b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color = #FF900> The ELK stack! <font color = #232F3E>\n",
    "\n",
    "We use ELK stack(ElasticSearch,Logstash and Kibana), three popular projects that analized all data-record and \n",
    "create a monitor view for the our projecs.\n",
    "\n",
    "<img src=\"../images/elastic-search-logo.png\" width=\"10%\" style=\"float: center; margin-left: 10px;\">\n",
    "<img src=\"../images/elastic-logstash-logo.png\" width=\"10%\" style=\"float: center; margin-left: 10px;\">\n",
    "<img src=\"../images/elastic-kibana-logo.png\" width=\"10%\" style=\"float: center; margin-left: 10px;\">\n",
    "\n",
    "\n",
    " In order, we talk about:\n",
    "\n",
    "# <font color = #FF900> Logstash <font color = #232F3E>\n",
    "\n",
    "Logstash is one of the best data ingestion tools. It belongs to the ELK stack and its strength relies on the following key attributes: \n",
    "\n",
    "- Versatile data ingestion from diverse sources.\n",
    "- Powerful data transformation capabilities.\n",
    "- Extensible through a wide range of plugins.\n",
    "- Scalable for handling large data volumes.\n",
    "\n",
    "We use Logstash to ingest the data coming from Amazon and send it to the \"reviews\" kafka topic\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4564b1f",
   "metadata": {},
   "source": [
    "# <font color = #FF900> Elasticsearch <font color = #232F3E>\n",
    "\n",
    "We use Elasticsearch as a powerful tool for searching and analyzing data quickly. In our project, we use it to store and manage data efficiently, allowing us to perform fast and flexible searches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80992e",
   "metadata": {},
   "source": [
    "# <font color = #FF900> Kibana <font color = #232F3E>\n",
    "    \n",
    "Kibana is the third part of the ELK stack and the final element in our data processing pipeline. Kibana is a user-friendly tool that helps us visualize data effectively and gain valuable statistical insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee68e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/kafka.png\" width=\"10%\" style=\"float: right; margin-left: 10px;\">\n",
    "\n",
    "\n",
    "# <font color = #FF900> Kafka <font color = #232F3E>\n",
    "To manage the flow of data between Logstash, Spark, and DetectAI, we employ Kafka. Kafka acts as a crucial intermediary, ensuring seamless and efficient data transfer among these components. \n",
    "We have 2 kafka topics:\n",
    "\n",
    "-reviews (its used to stream the reviews beetween logstash and detectAI)\n",
    "-detectedreviews (its used to stream the processed reviews from detectAI to Spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8efa8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/spark.png\" width=\"10%\" style=\"float: right; margin-left: 10px;\">\n",
    "\n",
    "# <font color = #FF900> Apache Spark <font color = #232F3E>\n",
    "\n",
    "Spark, is an open-source distributed computing system, plays a vital role in our project's data processing phase.\n",
    "In our project we use Spark to analyze our data and perform sentiment analysis of the reviews coming from Amazon.\n",
    "After processing the reviews it sends them to Elasticsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5ffb5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <font color = #FF900> Dashboard <font color = #232F3E>\n",
    "\n",
    "For sentiment analysis in our project, we utilized a pre-trained model from the SpaCy library.\n",
    "Additionally, we developed two functions that leverage the TextBlob library to compute\n",
    "the polarity and subjectivity of a provided set of reviews.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a4759",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dashboard visualization:\n",
    "\n",
    "<img src=\"../images/dashboard.jpg\" width=75% style=\"margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0e9c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <font color = #FF900> Thanks for the attention!\n",
    "    \n",
    "    \n",
    "<img src=\"../images/logo.png\" width=15% style=\"float: right; margin-left: 10px;\">  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
